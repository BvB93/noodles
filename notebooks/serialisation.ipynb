{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serialising the Stars\n",
    "\n",
    "Noodles lets you run jobs remotely and store/retrieve results in case of duplicate jobs or reruns. These features rely on the *serialisation* (and not unimportant, reconstruction) of all objects that are passed between scheduled functions. Serialisation refers to the process of turning any object into a stream of bytes from which we can reconstruct a functionally identical object. \"Easy enough!\" you might think, just use `pickle`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">function: b&#x27;\\x80\\x03cbuiltins\\ngetattr\\nq\\x00cbuiltins\\nstr\\nq\\x01X\\x0 … q\\x04.&#x27;</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">message: b&#x27;\\x80\\x03X\\x0c\\x00\\x00\\x00Hello, Wold!q\\x00.&#x27;</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from noodles.tutorial import display_text\n",
    "import pickle\n",
    "\n",
    "function = pickle.dumps(str.upper)\n",
    "message = pickle.dumps(\"Hello, Wold!\")\n",
    "\n",
    "display_text(\"function: \" + str(function))\n",
    "display_text(\"message: \" + str(message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO, WOLD!'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.loads(function)(pickle.loads(message))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However `pickle` cannot serialise all objects ... \"Use `dill`!\" you say; still the pickle/dill method of serializing is rather indiscriminate. Some of our objects may contain runtime data we can't or don't want to store, coroutines, threads, locks, open files, you name it. We work with a Sqlite3 database to store our data. An application might store gigabytes of numerical data.  We don't want those binary blobs in our database, rather to store them externally in a HDF5 file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many cases where a more fine-grained control of serialisation is in order. The bottom line being, that there is *no silver bullet solution*. Here we show some examples on how to customize the Noodles serialisation mechanism.\n",
    "\n",
    "## The registry\n",
    "\n",
    "Noodles keeps a registry of `Serialiser` objects that know exactly how to serialise and reconstruct objects. This registry is specified to the backend when we call the one of the `run` functions. To make the serialisation registry visible to remote parties it is important that the registry can be imported. This is why it has to be a function of zero arguments (a *thunk*) returning the actual registry object.\n",
    "\n",
    "```python\n",
    "def registry():\n",
    "    return Registry(...)\n",
    "    \n",
    "run(workflow,\n",
    "    db_file='project-cache.db',\n",
    "    registry=registry)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registry that should always be included is `noodles.serial.base`. This registry knows how to serialise basic Python dictionaries, lists, tuples, sets, strings, bytes, slices and all objects that are internal to Noodles. Special care is taken with objects that have a `__name__` attached and can be imported using the `__module__.__name__` combination.\n",
    "\n",
    "Registries can be composed using the `+` operator. For instance, suppose we want to use `pickle` as a default option for objects that are not in `noodles.serial.base`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noodles\n",
    "\n",
    "def registry():\n",
    "    return noodles.serial.pickle() \\\n",
    "        + noodles.serial.base()\n",
    "\n",
    "reg = registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what is made of our objects!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">[</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;These data are JSON compatible!&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  0,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  1.3,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  null,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  {</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;dictionaries&quot;:&quot;too!&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  }</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">]</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_text(reg.to_json([\n",
    "    \"These data are JSON compatible!\", 0, 1.3, None,\n",
    "    {\"dictionaries\": \"too!\"}], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! JSON compatible data stays the same. Now try an object that JSON doesn't know about."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{</pre>\n",
       "<pre style=\"background: #eeeeee; color: black;font-weight: bold; font-size: 9pt; margin: 0pt\">  &quot;_noodles&quot;:&quot;0.3.0&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;type&quot;:&quot;&lt;object&gt;&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;class&quot;:&quot;builtins.set&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;data&quot;:[</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    1,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    2,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    3</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  ]</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_text(reg.to_json({1, 2, 3}, indent=2), [1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects are encoded as a dictionary containing a `'_noodles'` key. So what will happen if we serialise an object the registry cannot possibly know about? Next we define a little astronomical class describing a star in the [Morgan-Keenan classification scheme](https://en.wikipedia.org/wiki/Stellar_classification)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;_noodles&quot;:&quot;0.3.0&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;type&quot;:&quot;&lt;object&gt;&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;class&quot;:&quot;__main__.Star&quot;,</pre>\n",
       "<pre style=\"background: #eeeeee; color: black;font-weight: bold; font-size: 9pt; margin: 0pt\">  &quot;data&quot;:&quot;gANjX19tYWluX18KU3RhcgpxACmBcQF9cQIoWA0A … EHdWIu&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Star(object):\n",
    "    \"\"\"Morgan-Keenan stellar classification.\"\"\"\n",
    "    def __init__(self, spectral_type, number, luminocity_class):\n",
    "        assert spectral_type in \"OBAFGKM\"\n",
    "        assert number in range(10)\n",
    "        \n",
    "        self.spectral_type = spectral_type\n",
    "        self.number = number\n",
    "        self.luminocity_class = luminocity_class\n",
    "\n",
    "rigel = Star('B', 8, 'Ia')\n",
    "display_text(reg.to_json(rigel, indent=2), [4], max_width=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The registry obviously doesn't know about `Star`s, so it falls back to serialisation using `pickle`. The pickled data is further encoded using `base64`. This solution won't work if some of your data cannot be pickled. Also, if you're sensitive to aesthetics, the pickled output doesn't look very nice.\n",
    "\n",
    "## *serialize* and *construct*\n",
    "\n",
    "One way to take control of the serialisation of your objects is to add the `__serialize__` and `__construct__` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Star(object):\n",
    "    \"\"\"Morgan-Keenan stellar classification.\"\"\"\n",
    "    def __init__(self, spectral_type, number, luminocity_class):\n",
    "        assert spectral_type in \"OBAFGKM\"\n",
    "        assert number in range(10)\n",
    "        \n",
    "        self.spectral_type = spectral_type\n",
    "        self.number = number\n",
    "        self.luminocity_class = luminocity_class\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f'{self.spectral_type}{self.number}{self.luminocity_class}'\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f'Star.from_string(\\'{str(self)}\\')'\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_string(string):\n",
    "        \"\"\"Construct a new Star from a string describing the stellar type.\"\"\"\n",
    "        return Star(string[0], int(string[1]), string[2:])\n",
    "    \n",
    "    def __serialize__(self, pack):\n",
    "        return pack(str(self))\n",
    "    \n",
    "    @classmethod\n",
    "    def __construct__(cls, data):\n",
    "        return Star.from_string(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class became quite a bit bigger. However, the `__str__`, `__repr__` and `from_string` methods are part of an interface you'd normally implement to make your class more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Sun is a G2V type star.\n"
     ]
    }
   ],
   "source": [
    "sun = Star('G', 2, 'V')\n",
    "print(\"The Sun is a\", sun, \"type star.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;_noodles&quot;:&quot;0.3.0&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;type&quot;:&quot;&lt;automagic&gt;&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;class&quot;:&quot;__main__.Star&quot;,</pre>\n",
       "<pre style=\"background: #eeeeee; color: black;font-weight: bold; font-size: 9pt; margin: 0pt\">  &quot;data&quot;:&quot;G2V&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_star = reg.to_json(sun, indent=2)\n",
    "display_text(encoded_star, [4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `__serialize__` method takes one argument (besides `self`). The argument `pack` is a function that creates the data record with all handles attached. The reason for this construct is that it takes keyword arguments for special cases.\n",
    "\n",
    "```python\n",
    "def pack(data, ref=None, files=None):\n",
    "    pass\n",
    "```\n",
    "\n",
    "* The `ref` argument, if given as `True`, will make sure that this object will not get reconstructed unnecessarily. One instance where this is incredibly useful, is if the object is a gigabytes large Numpy array.\n",
    "* The `files` argument, when given, should be a list of filenames. This makes sure Noodles knows about the involvement of external files.\n",
    "\n",
    "The data passed to `pack` maybe of any type, as long as the serialisation registry knows how to serialise it.\n",
    "\n",
    "The `__construct__` method must be a *class method*. The `data` argument it is given can be expected to be identical to the data passed to the `pack` function at serialisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">Star.from_string(&#x27;G2V&#x27;)</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "decoded_star = reg.from_json(encoded_star)\n",
    "display_text(repr(decoded_star))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data classes\n",
    "\n",
    "Since Python 3.7, it is possible to define classes that are meant to contain \"just data\" as a `dataclass`. We'll forgo any data validation at this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, is_dataclass\n",
    "\n",
    "@dataclass\n",
    "class Star:\n",
    "    \"\"\"Morgan-Keenan stellar classification.\"\"\"\n",
    "    spectral_type: str\n",
    "    number: int\n",
    "    luminocity_class: str\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'{self.spectral_type}{self.number}{self.luminocity_class}'\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_string(string):\n",
    "        \"\"\"Construct a new Star from a string describing the stellar type.\"\"\"\n",
    "        return Star(string[0], int(string[1]), string[2:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data classes are recognised by Noodles and will be automatically serialised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;_noodles&quot;:&quot;0.3.0&quot;,</pre>\n",
       "<pre style=\"background: #eeeeee; color: black;font-weight: bold; font-size: 9pt; margin: 0pt\">  &quot;type&quot;:&quot;&lt;dataclass&gt;&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;class&quot;:&quot;__main__.Star&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;data&quot;:{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;spectral_type&quot;:&quot;A&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;number&quot;:7,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;luminocity_class&quot;:&quot;V&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  }</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "altair = Star.from_string(\"A7V\")\n",
    "encoded_star = reg.to_json(altair, indent=2)\n",
    "display_text(encoded_star, [2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a Serialiser class (example with large data)\n",
    "\n",
    "Often, the class that needs serialising is not from your own package. In that case we need to write a specialised `Serialiser` class. For this purpose it may be nice to see how to serialise a Numpy array. This code is [already in Noodles](https://github.com/NLeSC/noodles/blob/master/noodles/serial/numpy.py); we will look at a trimmed down version.\n",
    "\n",
    "Given a NumPy array, we need to do two things:\n",
    "\n",
    "* Generate a token by which to identify the array; we will use a SHA-256 hash to do this.\n",
    "* Store the array effeciently; the HDF5 fileformat is perfectly suited.\n",
    "\n",
    "### SHA-256\n",
    "We need to hash the combination of datatype, array shape and the binary data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import hashlib\n",
    "import base64\n",
    "\n",
    "def array_sha256(a):\n",
    "    \"\"\"Create a SHA256 hash from a Numpy array.\"\"\"\n",
    "    dtype = str(a.dtype).encode()\n",
    "    shape = numpy.array(a.shape)\n",
    "    sha = hashlib.sha256()\n",
    "    sha.update(dtype)\n",
    "    sha.update(shape)\n",
    "    sha.update(a.tobytes())\n",
    "    return base64.urlsafe_b64encode(sha.digest()).decode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is this useable for large data? Let's see how this scales (code to generate this plot is below):\n",
    "\n",
    "![SHA-256 performance plot](./sha256-performance.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So on my laptop, hashing an array of ~1 GB takes a little over three seconds, and it scales almost perfectly linear. Next we define the storage routine (and a loading routine, but that's a oneliner)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def save_array_to_hdf5(filename, lock, array):\n",
    "    \"\"\"Save an array to a HDF5 file, using the SHA-256 of the array\n",
    "    data as path within the HDF5. The `lock` is needed to prevent\n",
    "    simultaneous access from multiple threads.\"\"\"\n",
    "    hdf5_path = array_sha256(array)\n",
    "    with lock, h5py.File(filename) as hdf5_file:\n",
    "        if not hdf5_path in hdf5_file:\n",
    "            dataset = hdf5_file.create_dataset(\n",
    "                hdf5_path, shape=array.shape, dtype=array.dtype)\n",
    "            dataset[...] = array\n",
    "            hdf5_file.close()\n",
    "\n",
    "    return hdf5_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And put it all together in a class derived from `SerArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import filelock\n",
    "from noodles.serial import Serialiser, Registry\n",
    "\n",
    "\n",
    "class SerArray(Serialiser):\n",
    "    \"\"\"Serialises Numpy array to HDF5 file.\"\"\"\n",
    "    def __init__(self, filename, lockfile):\n",
    "        super().__init__(numpy.ndarray)\n",
    "        self.filename = filename\n",
    "        self.lock = filelock.FileLock(lockfile)\n",
    "\n",
    "    def encode(self, obj, pack):\n",
    "        key = save_array_to_hdf5(self.filename, self.lock, obj)\n",
    "        return pack({\n",
    "            \"filename\": self.filename,\n",
    "            \"hdf5_path\": key,\n",
    "        }, files=[self.filename], ref=True)\n",
    "\n",
    "    def decode(self, cls, data):\n",
    "        with self.lock, h5py.File(self.filename) as hdf5_file:\n",
    "            return hdf5_file[data[\"hdf5_path\"]].value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to insert the serialiser into a new registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f tutorial.h5  # remove from previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import noodles\n",
    "from noodles.tutorial import display_text\n",
    "\n",
    "def registry():\n",
    "    return Registry(\n",
    "        parent=noodles.serial.base(),\n",
    "        types={\n",
    "            numpy.ndarray: SerArray('tutorial.h5', 'tutorial.lock')\n",
    "        })\n",
    "\n",
    "reg = registry()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can serialise our first Numpy array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;_noodles&quot;:&quot;0.3.0&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;type&quot;:&quot;&lt;object&gt;&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;class&quot;:&quot;numpy.ndarray&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;data&quot;:{</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;filename&quot;:&quot;tutorial.h5&quot;,</pre>\n",
       "<pre style=\"background: #eeeeee; color: black;font-weight: bold; font-size: 9pt; margin: 0pt\">    &quot;hdf5_path&quot;:&quot;4Z8kdMg-CbjgTKKYlz6b-_-Tsda5VAJL44OheRB10mU=&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  },</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;ref&quot;:true,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;host&quot;:&quot;localhost&quot;,</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  &quot;files&quot;:[</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">    &quot;tutorial.h5&quot;</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">  ]</pre>\n",
       "<pre style=\"font-size: 9pt; margin: 0pt\">}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_array = reg.to_json(numpy.arange(10), host='localhost', indent=2)\n",
    "display_text(encoded_array, [6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we should be able to read back the data directly from the HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('tutorial.h5') as f:\n",
    "    result = f['4Z8kdMg-CbjgTKKYlz6b-_-Tsda5VAJL44OheRB10mU='][()]\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set the `ref` property to `True`, we can now read back the serialised object without dereferencing. This will result in a placeholder object containing only the encoded data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">&lt;noodles.serial.registry.RefObject object at 0x7f7e6c5e8860&gt;</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">{&#x27;rec&#x27;: {&#x27;_noodles&#x27;: &#x27;0.3.0&#x27;, &#x27;type&#x27;: &#x27;&lt;object&gt;&#x27;,  … .h5&#x27;]}}</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ref = reg.from_json(encoded_array)\n",
    "display_text(ref)\n",
    "display_text(vars(ref), max_width=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to retrieve the data we should run `from_json` with `deref=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/johannes/.local/share/workon/windfarms/lib/python3.7/site-packages/h5py/_hl/dataset.py:313: H5pyDeprecationWarning: dataset.value has been deprecated. Use dataset[()] instead.\n",
      "  \"Use dataset[()] instead.\", H5pyDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"font-size: 9pt; margin: 0pt\">[0 1 2 3 4 5 6 7 8 9]</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_text(reg.from_json(encoded_array, deref=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix A: better parsing\n",
    "If you're interested in doing a bit better in parsing generic expressions into objects, take a look at `pyparsing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyparsing in /home/johannes/Code/Windfarms/pyparsing (2.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pyparsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will parse the stellar types we used before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyparsing import Literal, replaceWith, OneOrMore, Word, nums, oneOf\n",
    "\n",
    "def roman_numeral_literal(string, value):\n",
    "    return Literal(string).setParseAction(replaceWith(value))\n",
    "    \n",
    "one = roman_numeral_literal(\"I\", 1)\n",
    "four = roman_numeral_literal(\"IV\", 4)\n",
    "five = roman_numeral_literal(\"V\", 5)\n",
    "\n",
    "roman_numeral = OneOrMore(\n",
    "    (five | four | one).leaveWhitespace()) \\\n",
    "    .setName(\"roman\") \\\n",
    "    .setParseAction(lambda s, l, t: sum(t))\n",
    "\n",
    "integer = Word(nums) \\\n",
    "    .setName(\"integer\") \\\n",
    "    .setParseAction(lambda t:int(t[0]))\n",
    "\n",
    "mkStar = oneOf(list(\"OBAFGKM\")) + integer + roman_numeral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['B', 2, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(mkStar.parseString('B2IV'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "roman_class = {\n",
    "    'I': 'supergiant',\n",
    "    'II': 'bright giant',\n",
    "    'III': 'regular giant',\n",
    "    'IV': 'sub-giants',\n",
    "    'V': 'main-sequence',\n",
    "    'VI': 'sub-dwarfs',\n",
    "    'VII': 'white dwarfs'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix B: measuring SHA-256 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scaling: 0.9901834965025306 (should be ~1)\n",
      "speed: 0.3734309322279356 GB/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import timeit\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = \"serif\"\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def benchmark(size, number=10):\n",
    "    \"\"\"Measure performance of SHA-256 hashing large arrays.\"\"\"\n",
    "    data = numpy.random.uniform(size=size)\n",
    "    return timeit.timeit(\n",
    "        stmt=lambda: array_sha256(data),\n",
    "        number=number) / number\n",
    "\n",
    "\n",
    "sizes = numpy.logspace(10, 25, 16, base=2, dtype=int)\n",
    "timings = numpy.array([[benchmark(size, 1) for size in sizes]\n",
    "                       for i in range(10)])\n",
    "\n",
    "sizes_MB = sizes * 8 / 1e6\n",
    "timings_ms = timings.mean(axis=0) * 1000\n",
    "timings_err = timings.std(axis=0) * 1000\n",
    "\n",
    "slope, intercept, _, _, _ = stats.linregress(\n",
    "    numpy.log(sizes_MB[5:]),\n",
    "    numpy.log(timings_ms[5:]))\n",
    "\n",
    "print(\"scaling:\", slope, \"(should be ~1)\")\n",
    "print(\"speed:\", numpy.exp(-intercept), \"GB/s\")\n",
    "\n",
    "ax = plt.subplot(111)\n",
    "ax.set_xscale('log', nonposx='clip')\n",
    "ax.set_yscale('log', nonposy='clip')\n",
    "ax.plot(sizes_MB, numpy.exp(intercept) * sizes_MB,\n",
    "        label='{:.03} GB/s'.format(numpy.exp(-intercept)))\n",
    "ax.errorbar(sizes_MB, timings_ms, yerr=timings_err,\n",
    "            marker='.', ls=':', c='k', label='data')\n",
    "ax.set_xlabel('size ($MB$)')\n",
    "ax.set_ylabel('time ($ms$)')\n",
    "ax.set_title('SHA-256 performance', fontsize=10)\n",
    "ax.legend()\n",
    "plt.savefig('sha256-performance.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation\n",
    "\n",
    "A `Registry` object roughly consists of three parts. It works like a dictionary searching for `Serialiser`s based on the class or baseclass of an object. If an object cannot be identified through its class or baseclasses the `Registry` has a function hook that may use any test to determine the proper `Serialiser`. When neither the hook nor the dictionary give a result, there is a default fall-back option."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
